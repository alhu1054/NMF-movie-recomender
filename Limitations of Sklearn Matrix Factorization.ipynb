{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9635a64-c025-459a-b295-93be8cf069bf",
   "metadata": {},
   "source": [
    "# Movie Recommender System using Non-negative Matrix Factorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b9a3ca4-78e6-4609-80cb-14b129b7f517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from pytest import approx\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn import decomposition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28249146-eaec-4143-b6e2-5d7a58f4a6fa",
   "metadata": {},
   "source": [
    "First we load the data used in week 3 movie recommendation and create the same Data object as in week 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f141857d-e5cf-4d5d-92f0-e7c7c00abb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "MV_users = pd.read_csv('data/users.csv')\n",
    "MV_movies = pd.read_csv('data/movies.csv')\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be5b11e5-5c84-43a0-bc65-b79ed5ce5185",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Data = namedtuple('Data', ['users','movies','train','test'])\n",
    "data = Data(MV_users, MV_movies, train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf729710-fd56-409b-881b-3e9c1619bffc",
   "metadata": {},
   "source": [
    "Same class initialization as in week 3 homework to create the user-movie matrix and then a function that does NMF from the sklearn library on such matrix and use the results to predict the missing values.  For the NMF I use a small regularization value, and start by looking at 5 components. To get the predicted values, the matrices H and W that result from NMF are multiplied to a get a matrix that gives the predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4d431d1-4a51-4e7b-b341-63d5827b08c3",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "981f62bb9d13421fa9110d69e82176d9",
     "grade": false,
     "grade_id": "cell-f9c7ee3867550bb6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class RecSys():\n",
    "    def __init__(self, data, nc):\n",
    "        self.data=data\n",
    "        self.allusers = list(self.data.users['uID'])\n",
    "        self.allmovies = list(self.data.movies['mID'])\n",
    "        self.genres = list(self.data.movies.columns.drop(['mID', 'title', 'year']))\n",
    "        self.mid2idx = dict(zip(self.data.movies.mID,list(range(len(self.data.movies)))))\n",
    "        self.uid2idx = dict(zip(self.data.users.uID,list(range(len(self.data.users)))))\n",
    "        self.Mr = self.rating_matrix()\n",
    "        self.predicted = self.NMF_fact_1(nc,0.001)\n",
    "        self.Mm = None \n",
    "        self.sim = np.zeros((len(self.allmovies),len(self.allmovies)))\n",
    "        \n",
    "    def rating_matrix(self):\n",
    "        \"\"\"\n",
    "        Convert the rating matrix to numpy array of shape (#allusers,#allmovies)\n",
    "        \"\"\"\n",
    "        \n",
    "        ind_movie = [self.mid2idx[x] for x in self.data.train.mID] \n",
    "        ind_user = [self.uid2idx[x] for x in self.data.train.uID]\n",
    "        rating_train = list(train.rating)\n",
    "        return np.array(coo_matrix((rating_train, (ind_user, ind_movie)), shape=(len(self.allusers), len(self.allmovies))).toarray())\n",
    "    \n",
    "    def predict_from_NMF(self,uid,mid):\n",
    "        \"\"\"\n",
    "        Use matrix factorization result to get the prediction.\n",
    "        Search the predicted value in the predicted matrix.\n",
    "        \"\"\"\n",
    "        return self.predicted[self.uid2idx[uid],self.mid2idx[mid]]\n",
    "        \n",
    "        \n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Predict ratings in the test data. Returns predicted rating in a numpy array of size (# of rows in testdata,)\n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        ind_user =  self.data.test.uID\n",
    "        ind_movie = self.data.test.mID\n",
    "        rat_test = np.zeros(len(ind_user),)\n",
    "        for i in range(0,len(ind_movie)):\n",
    "            rat_test[i] = self.predict_from_NMF(ind_user[i],ind_movie[i])\n",
    "        return rat_test\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def NMF_fact_1(self,n_comp,alpha):\n",
    "        \"\"\"\n",
    "        Uses NMF factorization once to create a predicted matrix. By factoriz the matrix self.Mr\n",
    "        in two matrices with n_componets. And then multiplying them back together to get \n",
    "        the values of the missing ratings.  \n",
    "        \"\"\"\n",
    "        self.nmf_mod = decomposition.NMF(n_components = n_comp, alpha = alpha, max_iter = 450, init = 'nndsvd',random_state = 45)\n",
    "        W = self.nmf_mod.fit_transform(self.Mr)\n",
    "        H = self.nmf_mod.components_\n",
    "        return W.dot(H).clip(1,5)\n",
    "\n",
    "    \n",
    "    def rmse(self,yp):\n",
    "        yp[np.isnan(yp)]=3 #In case there is nan values in prediction, it will impute to 3.\n",
    "        yt=np.array(self.data.test.rating)\n",
    "        return np.sqrt(((yt-yp)**2).mean())\n",
    "    \n",
    "    \n",
    "    def update_NMF(self,ite_num):\n",
    "        W = self.nmf_mod.fit_transform(self.Mr)\n",
    "        H = self.nmf_mod.components_\n",
    "        for i in range(0,ite_num):\n",
    "            new = W.dot(H)\n",
    "            aux = np.where(self.Mr==0, new, self.Mr)\n",
    "            W = self.nmf_mod.fit_transform(aux)\n",
    "            H = self.nmf_mod.components_\n",
    "            \n",
    "        return(W.dot(H).clip(1,5))\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "      \n",
    "                \n",
    "\n",
    "        \n",
    "            \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a24c7f2-f048-45e0-b63f-70040e69e799",
   "metadata": {},
   "source": [
    "I start by setting the number of components of the NMF algorithm to 5 and check the rmse value of the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28ac6c03-e628-45aa-8ead-83d40765c550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6086382547148195\n"
     ]
    }
   ],
   "source": [
    "rs = RecSys(data,nc = 5)\n",
    "yp = rs.predict()\n",
    "print(rs.rmse(yp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f7336b-02e5-4f0b-8e5d-3c5993d92c79",
   "metadata": {},
   "source": [
    "Thats a really high value, twice the value of setting all the values to 3.  For any data between 1 and 5 if you set the values to 3 the biggest error you can get is 2 in case the result would be 5. Here the error is even more than half the range of the data. As rmse is just the square root of the sum of the square of all the diferences between the real value and the predicted value given by the matrix created by multiplying W and H over the total number of predictions tried, so Is a way of getting the average error of the recommendation. The largest average error possible for this data is 4, as the data goes from 1 to 5. So having and average error of 2.6 is worst than random guessing. \n",
    "\n",
    "\n",
    "To try to improve the error we do a search over the number of components to see which one gives a lower rmse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8f6054b-f2dc-414b-9848-cb43427a5afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Aline/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:1090: ConvergenceWarning: Maximum number of iterations 450 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n",
      "/Users/Aline/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:1090: ConvergenceWarning: Maximum number of iterations 450 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n",
      "/Users/Aline/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:1090: ConvergenceWarning: Maximum number of iterations 450 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n",
      "/Users/Aline/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:1090: ConvergenceWarning: Maximum number of iterations 450 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n",
      "/Users/Aline/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:1090: ConvergenceWarning: Maximum number of iterations 450 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n",
      "/Users/Aline/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:1090: ConvergenceWarning: Maximum number of iterations 450 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n",
      "/Users/Aline/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:1090: ConvergenceWarning: Maximum number of iterations 450 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n",
      "/Users/Aline/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:1090: ConvergenceWarning: Maximum number of iterations 450 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.6086382547148195,\n",
       " 2.5964616402416008,\n",
       " 2.5901953317583577,\n",
       " 2.5817188701804263,\n",
       " 2.5738092088660385,\n",
       " 2.5668140072312458,\n",
       " 2.5612185264751126,\n",
       " 2.5566684022432518,\n",
       " 2.5521605279408894,\n",
       " 2.5495342355105066,\n",
       " 2.5450920272646114,\n",
       " 2.54084947553645,\n",
       " 2.537734076097635,\n",
       " 2.5346597390051997,\n",
       " 2.5380583911355736,\n",
       " 2.536809579414082,\n",
       " 2.535618851531393,\n",
       " 2.5340838449058523,\n",
       " 2.536681407314102,\n",
       " 2.5347781458123055,\n",
       " 2.5359918467952873,\n",
       " 2.542350083992273,\n",
       " 2.538539995958405,\n",
       " 2.5363713696877257,\n",
       " 2.5451398038707067]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = [rs.rmse(yp)]\n",
    "for n_c in range (6,30):\n",
    "    rs.predicted = rs.NMF_fact_1(n_c, alpha = 0.001)\n",
    "    yp = rs.predict()\n",
    "    rmse.append(rs.rmse(yp))\n",
    "rmse   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed33262-4175-4d3f-9d43-8c2139721a39",
   "metadata": {},
   "source": [
    "Even whe changing the loss function, and the regularization parameter the rmse values keep being higher than the results we found in homework 3. The best results  were around 2.534 for 18 and 22 number of components, thats still a terrible result. As we can see from the warnings even when set at 450 the number of iterations aren't enough to get to the tolerance level of the algorithm. The matrix we are working with to make the recommendations is quite big and sparse so the results aren't good. As the resulting from multiplying HW we are getting a matrix with a lot of small values that become one when we restrict the values to be between 1 and 5. A way to improve the poor results due to the sparsity we can create a new matrix to fit that would be created by combining the original matrix rs.MR that we want to fit a fill the zeros of such matrix with the results of the matrix thats a result o H times W. And repeat it with the new factorization. \n",
    "https://archive.siam.org/meetings/sdm06/proceedings/059zhangs2.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fadc3fe-b65d-4d8d-a293-7c916e6b5e5b",
   "metadata": {},
   "source": [
    "We start by setting the number of components to 18. And then we do the recursive method explained above to improve the prediction results of the NMF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cb2ef63-09ab-4cd6-b83f-0df5a77120d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5346597390051997\n",
      "1.0443547984464792\n"
     ]
    }
   ],
   "source": [
    "rs = RecSys(data,nc = 18)\n",
    "yp = rs.predict()\n",
    "print(rs.rmse(yp))\n",
    "rs.predicted = rs.update_NMF(50)\n",
    "yp = rs.predict()\n",
    "print(rs.rmse(yp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949a8da8-563c-462b-ab26-776462c15356",
   "metadata": {},
   "source": [
    "After 50 iterations the rmse improved from 2.53 to 1.04 which is a great improve but still worst than setting every user rating to its average value. So I wouldnt recommend NMF for recommendation systems where the data is sparse as all the collaborative methods used in homework 3 have better results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980c5d09-ccc6-4b99-b491-671c6173015a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
